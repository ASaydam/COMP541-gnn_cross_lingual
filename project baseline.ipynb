{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89a907cf",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a65fc784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\Alper\\.julia\\environments\\v1.6\\Project.toml`\n",
      " \u001b[90m [052768ef] \u001b[39m\u001b[92m+ CUDA v3.5.0\u001b[39m\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Alper\\.julia\\environments\\v1.6\\Manifest.toml`\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPyCall\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mCSV\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGraphMLDatasets\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mGeometricFlux\n",
      "\u001b[32m  ✓ \u001b[39mPlots\n",
      "  5 dependencies successfully precompiled in 28 seconds (210 already precompiled)\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\Alper\\.julia\\environments\\v1.6\\Project.toml`\n",
      " \u001b[90m [587475ba] \u001b[39m\u001b[92m+ Flux v0.12.8\u001b[39m\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Alper\\.julia\\environments\\v1.6\\Manifest.toml`\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPyCall\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mCSV\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGraphMLDatasets\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mGeometricFlux\n",
      "\u001b[32m  ✓ \u001b[39mPlots\n",
      "  5 dependencies successfully precompiled in 29 seconds (210 already precompiled)\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LightXML ───────── v0.9.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m InternedStrings ── v0.7.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m BSON ───────────── v0.3.4\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m TupleTools ─────── v1.3.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Strided ────────── v1.1.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Pickle ─────────── v0.2.8\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m BytePairEncoding ─ v0.2.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Transformers ───── v0.1.13\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\Alper\\.julia\\environments\\v1.6\\Project.toml`\n",
      " \u001b[90m [21ca0261] \u001b[39m\u001b[92m+ Transformers v0.1.13\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\Alper\\.julia\\environments\\v1.6\\Manifest.toml`\n",
      " \u001b[90m [fbb218c0] \u001b[39m\u001b[92m+ BSON v0.3.4\u001b[39m\n",
      " \u001b[90m [a4280ba5] \u001b[39m\u001b[92m+ BytePairEncoding v0.2.0\u001b[39m\n",
      " \u001b[90m [7d512f48] \u001b[39m\u001b[92m+ InternedStrings v0.7.0\u001b[39m\n",
      " \u001b[90m [9c8b4983] \u001b[39m\u001b[92m+ LightXML v0.9.0\u001b[39m\n",
      " \u001b[90m [fbb45041] \u001b[39m\u001b[92m+ Pickle v0.2.8\u001b[39m\n",
      " \u001b[90m [5e0ebb24] \u001b[39m\u001b[92m+ Strided v1.1.2\u001b[39m\n",
      " \u001b[90m [21ca0261] \u001b[39m\u001b[92m+ Transformers v0.1.13\u001b[39m\n",
      " \u001b[90m [9d95972d] \u001b[39m\u001b[92m+ TupleTools v1.3.0\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mInternedStrings\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mTupleTools\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mBSON\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLightXML\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStrided\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mBytePairEncoding\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPickle\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPyCall\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mCSV\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGraphMLDatasets\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mTransformers\n",
      "\u001b[32m  ✓ \u001b[39mGeometricFlux\n",
      "\u001b[32m  ✓ \u001b[39mPlots\n",
      "  13 dependencies successfully precompiled in 30 seconds (210 already precompiled)\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "\n",
    "using Pkg\n",
    "Pkg.add(\"CUDA\")\n",
    "Pkg.add(\"Flux\")\n",
    "Pkg.add(\"Transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45e16097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Transformers [21ca0261-441d-5938-ace7-c90938fde4d4]\n",
      "└ @ Base loading.jl:1342\n",
      "\u001b[32m\u001b[1m Downloading\u001b[22m\u001b[39m artifact: CUDA\n"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using CUDA\n",
    "using Transformers\n",
    "using Transformers.Basic #for loading the positional embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2c0076",
   "metadata": {},
   "source": [
    "## System Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f009ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: NT\n",
      "Julia: 1.6.3\n",
      "Knet: 1.4.9\n",
      "GPU: Quadro RTX 3000\n",
      "\n",
      "CUDA toolkit 11.4, artifact installation\n",
      "NVIDIA driver 496.49.0, for CUDA 11.5\n",
      "CUDA driver 11.5\n",
      "\n",
      "Libraries: \n",
      "- CUBLAS: 11.5.4\n",
      "- CURAND: 10.2.5\n",
      "- CUFFT: 10.5.1\n",
      "- CUSOLVER: 11.2.0\n",
      "- CUSPARSE: 11.6.0\n",
      "- CUPTI: 14.0.0\n",
      "- NVML: 11.0.0+496.49\n",
      "- CUDNN: 8.20.2 (for CUDA 11.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Downloading\u001b[22m\u001b[39m artifact: CUTENSOR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- CUTENSOR: 1.3.0 (for CUDA 11.2.0)\n",
      "\n",
      "Toolchain:\n",
      "- Julia: 1.6.3\n",
      "- LLVM: 11.0.1\n",
      "- PTX ISA support: 3.2, 4.0, 4.1, 4.2, 4.3, 5.0, 6.0, 6.1, 6.3, 6.4, 6.5, 7.0\n",
      "- Device capability support: sm_35, sm_37, sm_50, sm_52, sm_53, sm_60, sm_61, sm_62, sm_70, sm_72, sm_75, sm_80\n",
      "\n",
      "1 device:\n",
      "  0: Quadro RTX 3000 (sm_75, 4.740 GiB / 6.000 GiB available)\n",
      "CUDA: nothing\n"
     ]
    }
   ],
   "source": [
    "println(\"OS: \", Sys.KERNEL)\n",
    "println(\"Julia: \", VERSION)\n",
    "println(\"Knet: \", Pkg.dependencies()[Base.UUID(\"1902f260-5fb4-5aff-8c31-6271790ab950\")].version)\n",
    "println(\"GPU: \", read(`nvidia-smi --query-gpu=name --format=csv,noheader`,String))\n",
    "println(\"CUDA: \", CUDA.versioninfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfe819b",
   "metadata": {},
   "source": [
    "# Toy test case : Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dcd01d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocabulary{Int64}(13, unk=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = collect(1:10)\n",
    "startsym = 11\n",
    "endsym = 12\n",
    "unksym = 0\n",
    "labels = [unksym, startsym, endsym, labels...]\n",
    "vocab = Transformers.Basic.Vocabulary(labels, unksym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "802b3876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample = preprocess.(sample_data()) = ([11, 10, 2, 10, 3, 1, 6, 9, 2, 5, 8, 12], [11, 10, 2, 10, 3, 1, 6, 9, 2, 5, 8, 12])\n",
      "encoded_sample = vocab(sample[1]) = [2, 13, 5, 13, 6, 4, 9, 12, 5, 8, 11, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12-element Vector{Int64}:\n",
       "  2\n",
       " 13\n",
       "  5\n",
       " 13\n",
       "  6\n",
       "  4\n",
       "  9\n",
       " 12\n",
       "  5\n",
       "  8\n",
       " 11\n",
       "  3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function for generate training datas\n",
    "sample_data() = (d = rand(1:10, 10); (d,d))\n",
    "#function for adding start & end symbol\n",
    "preprocess(x) = [startsym, x..., endsym]\n",
    "\n",
    "@show sample = preprocess.(sample_data())\n",
    "@show encoded_sample = vocab(sample[1]) #use Vocabulary to encode the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b1827",
   "metadata": {},
   "source": [
    "# Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "badb5271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Downloading\u001b[22m\u001b[39m artifact: CUDNN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "decoder_forward (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define a Word embedding layer which turn word index to word vector\n",
    "embed = Embed(512, length(vocab)) |> gpu\n",
    "#define a position embedding layer metioned above\n",
    "pe = PositionEmbedding(512) |> gpu\n",
    "\n",
    "#wrapper for get embedding\n",
    "function embedding(x)\n",
    "  we = embed(x, inv(sqrt(512))) \n",
    "  e = we .+ pe(we)\n",
    "    return e\n",
    "end\n",
    "\n",
    "#define 2 layer of transformer\n",
    "encode_t1 = Transformer(512, 8, 64, 2048) |> gpu  \n",
    "encode_t2 = Transformer(512, 8, 64, 2048) |> gpu\n",
    "\n",
    "#define 2 layer of transformer decoder\n",
    "decode_t1 = TransformerDecoder(512, 8, 64, 2048) |> gpu  \n",
    "decode_t2 = TransformerDecoder(512, 8, 64, 2048) |> gpu\n",
    "\n",
    "#define the layer to get the final output probabilities\n",
    "linear = Positionwise(Dense(512, length(vocab)), logsoftmax) |> gpu\n",
    "\n",
    "function encoder_forward(x)\n",
    "  e = embedding(x)\n",
    "  t1 = encode_t1(e)\n",
    "  t2 = encode_t2(t1)\n",
    "  return t2\n",
    "end\n",
    "\n",
    "function decoder_forward(x, m)\n",
    "  e = embedding(x)\n",
    "  t1 = decode_t1(e, m)\n",
    "  t2 = decode_t2(t1, m)\n",
    "  p = linear(t2)\n",
    "    return p\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859dc843",
   "metadata": {},
   "source": [
    "# Run the model on a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "919fb1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13×12 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       " -2.3323   -2.34909  -2.44869  -2.49098  …  -1.99231  -1.97707  -2.10335\n",
       " -3.5336   -3.59267  -3.65139  -3.57039     -3.23912  -3.29698  -3.37359\n",
       " -1.91805  -1.99483  -2.03525  -2.1835      -2.35824  -2.26476  -2.07237\n",
       " -1.2258   -1.21493  -1.17436  -1.15963     -1.42308  -1.47211  -1.47968\n",
       " -2.99453  -3.14909  -3.33024  -3.32453     -3.74291  -3.87724  -3.8802\n",
       " -2.56449  -2.39744  -2.37409  -2.30737  …  -2.48594  -2.2813   -2.10433\n",
       " -4.86829  -4.82257  -4.98728  -5.13294     -5.1413   -5.21062  -5.302\n",
       " -3.9087   -3.85332  -3.71741  -3.74136     -4.03006  -3.96037  -3.77018\n",
       " -2.48812  -2.55806  -2.66239  -2.76245     -2.23914  -2.41032  -2.62349\n",
       " -2.1162   -2.04534  -1.98752  -1.91218     -1.89573  -1.93287  -2.00474\n",
       " -2.80382  -2.83438  -2.7462   -2.65263  …  -2.57856  -2.48288  -2.44479\n",
       " -5.08103  -5.11392  -5.0582   -5.03105     -4.27402  -4.27918  -4.27636\n",
       " -4.80408  -4.64663  -4.54454  -4.63024     -4.44452  -4.42397  -4.4566"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = encoder_forward(encoded_sample)\n",
    "probs = decoder_forward(encoded_sample, enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1a9e6d",
   "metadata": {},
   "source": [
    "# Define the loss and train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "339c5706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train! (generic function with 1 method)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: find the problem with the onehot func.\n",
    "\n",
    "function smooth(et)\n",
    "    sm = fill!(similar(et, Float32), 1e-6/size(embed, 2))\n",
    "    p = sm .* (1 .+ -et)\n",
    "    label = p .+ et .* (1 - convert(Float32, 1e-6))\n",
    "    label\n",
    "end\n",
    "\n",
    "#define loss function\n",
    "function loss(x, y)\n",
    "  label = Flux.onehot(vocab, y) #turn the index to one-hot encoding\n",
    "  label = smooth(label) #perform label smoothing\n",
    "  enc = encoder_forward(x)\n",
    "\tprobs = decoder_forward(y, enc)\n",
    "  l = logkldivergence(label[:, 2:end, :], probs[:, 1:end-1, :])\n",
    "  return l\n",
    "end\n",
    "\n",
    "#collect all the parameters\n",
    "ps = params(embed, pe, encode_t1, encode_t2, decode_t1, decode_t2, linear)\n",
    "opt = ADAM(1e-4)\n",
    "\n",
    "#function for created batched data\n",
    "using Transformers.Datasets: batched\n",
    "\n",
    "#flux function for update parameters\n",
    "using Flux: gradient\n",
    "using Flux.Optimise: update!\n",
    "\n",
    "#define training loop\n",
    "function train!()\n",
    "  @info \"start training\"\n",
    "  for i = 1:2000\n",
    "    data = batched([sample_data() for i = 1:32]) #create 32 random sample and batched\n",
    "\t\tx, y = preprocess.(data[1]), preprocess.(data[2])\n",
    "    x, y = vocab(x), vocab(y)#encode the data\n",
    "    x, y = todevice(x, y) #move to gpu\n",
    "    l = loss(x, y)\n",
    "    grad = gradient(()->l, ps)\n",
    "    if i % 8 == 0\n",
    "    \tprintln(\"loss = $l\")\n",
    "    end\n",
    "    update!(opt, ps, grad)\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1774f259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: start training\n",
      "└ @ Main In[91]:31\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching OneHotArray(::Transformers.Basic.OneHot{0x0000000d})\n\u001b[0mClosest candidates are:\n\u001b[0m  OneHotArray(::Any, \u001b[91m::Transformers.Basic.OneHot\u001b[39m) at C:\\Users\\Alper\\.julia\\packages\\Transformers\\3YgSd\\src\\basic\\embeds\\onehot.jl:115\n\u001b[0m  OneHotArray(::Any, \u001b[91m::Any\u001b[39m) at C:\\Users\\Alper\\.julia\\packages\\Transformers\\3YgSd\\src\\basic\\embeds\\onehot.jl:114\n\u001b[0m  OneHotArray(\u001b[91m::A\u001b[39m) where {K, A<:(AbstractArray{Transformers.Basic.OneHot{K}, N} where N)} at C:\\Users\\Alper\\.julia\\packages\\Transformers\\3YgSd\\src\\basic\\embeds\\onehot.jl:112",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching OneHotArray(::Transformers.Basic.OneHot{0x0000000d})\n\u001b[0mClosest candidates are:\n\u001b[0m  OneHotArray(::Any, \u001b[91m::Transformers.Basic.OneHot\u001b[39m) at C:\\Users\\Alper\\.julia\\packages\\Transformers\\3YgSd\\src\\basic\\embeds\\onehot.jl:115\n\u001b[0m  OneHotArray(::Any, \u001b[91m::Any\u001b[39m) at C:\\Users\\Alper\\.julia\\packages\\Transformers\\3YgSd\\src\\basic\\embeds\\onehot.jl:114\n\u001b[0m  OneHotArray(\u001b[91m::A\u001b[39m) where {K, A<:(AbstractArray{Transformers.Basic.OneHot{K}, N} where N)} at C:\\Users\\Alper\\.julia\\packages\\Transformers\\3YgSd\\src\\basic\\embeds\\onehot.jl:112",
      "",
      "Stacktrace:",
      " [1] OneHotArray(k::Int64, xs::Int64)",
      "   @ Transformers.Basic C:\\Users\\Alper\\.julia\\packages\\Transformers\\3YgSd\\src\\basic\\embeds\\onehot.jl:114",
      " [2] onehot(v::Transformers.Basic.Vocabulary{Int64}, x::Matrix{Int64})",
      "   @ Transformers.Basic C:\\Users\\Alper\\.julia\\packages\\Transformers\\3YgSd\\src\\basic\\embeds\\vocab.jl:95",
      " [3] loss(x::Matrix{Int64}, y::Matrix{Int64})",
      "   @ Main .\\In[91]:10",
      " [4] train!()",
      "   @ Main .\\In[91]:37",
      " [5] top-level scope",
      "   @ In[92]:1",
      " [6] eval",
      "   @ .\\boot.jl:360 [inlined]",
      " [7] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1116"
     ]
    }
   ],
   "source": [
    "train!()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
